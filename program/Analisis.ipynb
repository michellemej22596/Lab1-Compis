{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1be57d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Análisis de la Gramática de ANTLR y el Archivo Driver**\n",
    "\n",
    "#### **1. La Gramática de ANTLR (`MiniLang.g4`)**\n",
    "\n",
    "El archivo **`MiniLang.g4`** es el archivo de gramática que ANTLR utiliza para generar un **Lexer** y un **Parser**. Este archivo se organiza en varias secciones importantes:\n",
    "\n",
    "* **Sección de `lexer rules`**:\n",
    "  Las reglas de **`lexer`** definen cómo se reconocen los **tokens** (unidades léxicas) del lenguaje. Los **tokens** pueden ser identificadores, números, operadores, etc. Ejemplo de una regla de **`lexer`**:\n",
    "\n",
    "  ```antlr\n",
    "  ID      : [a-zA-Z]+;        // Define un identificador\n",
    "  NUMBER  : [0-9]+;           // Define un número\n",
    "  ```\n",
    "\n",
    "  **Explicación**:\n",
    "\n",
    "  * El **`ID`** captura cadenas de caracteres alfabéticos.\n",
    "  * El **`NUMBER`** captura secuencias de dígitos.\n",
    "\n",
    "* **Sección de `parser rules`**:\n",
    "  Las reglas de **`parser`** definen cómo se agrupan los **tokens** para formar expresiones válidas en el lenguaje. Estas reglas son las que forman la estructura sintáctica del lenguaje. Ejemplo de una regla de **`parser`**:\n",
    "\n",
    "  ```antlr\n",
    "  expr    : term ('+' term)*;   // Expresión que suma términos\n",
    "  term    : NUMBER | ID;        // Un término es un número o un identificador\n",
    "  ```\n",
    "\n",
    "  **Explicación**:\n",
    "\n",
    "  * **`expr`**: Una expresión es un término seguido de una serie de sumas (opcional).\n",
    "  * **`term`**: Un término puede ser un **`NUMBER`** o un **`ID`**.\n",
    "\n",
    "* **Uso del `#` en ANTLR**:\n",
    "  El **`#`** en ANTLR se utiliza para **asignar un nombre** a un token o regla. Este nombre se puede usar luego para acceder a dicho elemento en el código generado por ANTLR. Ejemplo:\n",
    "\n",
    "  ```antlr\n",
    "  expr    : term ('+' term)* #add;\n",
    "  ```\n",
    "\n",
    "  **Explicación**: Aquí, **`#add`** asigna el nombre \"add\" a la regla `expr`, lo que permite hacer referencia a esta regla en el código generado.\n",
    "\n",
    "#### **2. Archivo Driver (`Driver.py`)**\n",
    "\n",
    "El archivo **`Driver.py`** es el **punto de entrada** de la aplicación. Su propósito principal es usar la gramática definida en **`MiniLang.g4`** para analizar un archivo de entrada y verificar si cumple con la sintaxis de **MiniLang**.\n",
    "\n",
    "**Función del archivo `Driver.py`**:\n",
    "\n",
    "* **Inicialización de ANTLR**: El archivo **`Driver.py`** importa las clases generadas por ANTLR (como `MiniLangLexer` y `MiniLangParser`), las cuales son responsables de dividir el texto fuente en **tokens** y luego analizarlos según las reglas de la gramática.\n",
    "\n",
    "* **Entrada de prueba**: El archivo **`program_test.txt`** contiene el código que será analizado. Este archivo se pasa al **Lexer** para dividirlo en **tokens**.\n",
    "\n",
    "* **Análisis Sintáctico**: Los **tokens** generados por el **Lexer** son pasados al **Parser** para comprobar que el código fuente se ajusta a las reglas de la gramática. Si no se encuentra ningún error, el programa termina sin mostrar resultados. Si hay un error, el **Parser** muestra el mensaje de error en la consola.\n",
    "\n",
    "#### **3. Archivos Generados por ANTLR**\n",
    "\n",
    "* **`MiniLangLexer.py`**: Este archivo genera un **Lexer** que convierte el archivo de entrada en **tokens**.\n",
    "* **`MiniLangParser.py`**: Este archivo genera un **Parser** que toma los **tokens** y construye un árbol de análisis sintáctico.\n",
    "* **`MiniLangListener.py`**: Contiene un **listener** que puede ser utilizado para recorrer el árbol de análisis y realizar acciones adicionales, como evaluaciones o transformaciones.\n",
    "\n",
    "#### **4. Funcionamiento de ANTLR y sus Elementos**\n",
    "\n",
    "* **`Lexer`**: Se encarga de dividir el texto de entrada en **tokens** (por ejemplo, identificadores, números, operadores).\n",
    "\n",
    "* **`Parser`**: Toma los **tokens** generados por el **Lexer** y los organiza en una estructura jerárquica (árbol de sintaxis), que representa la gramática del lenguaje.\n",
    "\n",
    "* **Reglas del Lexer y del Parser**:\n",
    "\n",
    "  * Las **`lexer rules`** definen qué patrones se deben reconocer (por ejemplo, palabras clave, identificadores).\n",
    "  * Las **`parser rules`** definen cómo se agrupan esos **tokens** para formar sentencias válidas.\n",
    "\n",
    "#### **Resumen de las Partes de la Gramática de ANTLR**\n",
    "\n",
    "* **Archivo `.g4`**: Es el archivo de definición de la gramática donde se especifican tanto las reglas de léxico como las de sintaxis.\n",
    "* **`# en ANTLR`**: Se utiliza para asignar un nombre a una regla o token, lo cual es útil para referirse a ella en el código generado.\n",
    "* **Lexer**: Divide el texto en **tokens**.\n",
    "* **Parser**: Organiza los **tokens** en una estructura jerárquica (árbol de análisis).\n",
    "* **Driver**: Utiliza el **Lexer** y el **Parser** para realizar el análisis sintáctico del código de entrada.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
